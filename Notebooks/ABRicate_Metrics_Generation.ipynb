{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMusVAPIkxk1",
        "outputId": "ae00cd1f-6d83-4842-c9a9-a6aa425b908c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluating CARDS for Staphylococcus aureus ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/cards_Staphylococcus_aureus_metrics.csv\n",
            "Saved confusion matrices to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/cards_Staphylococcus_aureus_confusion_matrices.txt\n",
            "Saved focused metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/cards_Staphylococcus_aureus_FOCUSED_metrics.csv\n",
            "\n",
            "=== Evaluating NCBI for Staphylococcus aureus ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/ncbi_Staphylococcus_aureus_metrics.csv\n",
            "Saved confusion matrices to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/ncbi_Staphylococcus_aureus_confusion_matrices.txt\n",
            "Saved focused metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/ncbi_Staphylococcus_aureus_FOCUSED_metrics.csv\n",
            "\n",
            "=== Evaluating RESFINDER for Staphylococcus aureus ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/resfinder_Staphylococcus_aureus_metrics.csv\n",
            "Saved confusion matrices to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/resfinder_Staphylococcus_aureus_confusion_matrices.txt\n",
            "Saved focused metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/resfinder_Staphylococcus_aureus_FOCUSED_metrics.csv\n",
            "Saved merged comparison table to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/comparison_Staphylococcus_aureus.csv\n",
            "\n",
            "=== Evaluating CARDS for Salmonella enterica ===\n",
            "Saved metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/cards_Salmonella_enterica_metrics.csv\n",
            "Saved confusion matrices to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/cards_Salmonella_enterica_confusion_matrices.txt\n",
            "Saved focused metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/cards_Salmonella_enterica_FOCUSED_metrics.csv\n",
            "\n",
            "=== Evaluating NCBI for Salmonella enterica ===\n",
            "Saved metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/ncbi_Salmonella_enterica_metrics.csv\n",
            "Saved confusion matrices to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/ncbi_Salmonella_enterica_confusion_matrices.txt\n",
            "Saved focused metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/ncbi_Salmonella_enterica_FOCUSED_metrics.csv\n",
            "\n",
            "=== Evaluating RESFINDER for Salmonella enterica ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/resfinder_Salmonella_enterica_metrics.csv\n",
            "Saved confusion matrices to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/resfinder_Salmonella_enterica_confusion_matrices.txt\n",
            "Saved focused metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/resfinder_Salmonella_enterica_FOCUSED_metrics.csv\n",
            "Saved merged comparison table to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/comparison_Salmonella_enterica.csv\n",
            "\n",
            "=== Evaluating CARDS for Escherichia coli ===\n",
            "Saved metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/cards_Escherichia_coli_metrics.csv\n",
            "Saved confusion matrices to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/cards_Escherichia_coli_confusion_matrices.txt\n",
            "Saved focused metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/cards_Escherichia_coli_FOCUSED_metrics.csv\n",
            "\n",
            "=== Evaluating NCBI for Escherichia coli ===\n",
            "Saved metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/ncbi_Escherichia_coli_metrics.csv\n",
            "Saved confusion matrices to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/ncbi_Escherichia_coli_confusion_matrices.txt\n",
            "Saved focused metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/ncbi_Escherichia_coli_FOCUSED_metrics.csv\n",
            "\n",
            "=== Evaluating RESFINDER for Escherichia coli ===\n",
            "Saved metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/resfinder_Escherichia_coli_metrics.csv\n",
            "Saved confusion matrices to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/resfinder_Escherichia_coli_confusion_matrices.txt\n",
            "Saved focused metrics to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/resfinder_Escherichia_coli_FOCUSED_metrics.csv\n",
            "Saved merged comparison table to /content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation/comparison_Escherichia_coli.csv\n"
          ]
        }
      ],
      "source": [
        "# --- Focused drug sets per species ---\n",
        "FOCUSED_DRUGS = {\n",
        "    \"Escherichia coli\": [\n",
        "        \"Ciprofloxacin\", \"Gentamicin\", \"Cefuroxime\", \"Ampicillin\"\n",
        "    ],\n",
        "    \"Salmonella enterica\": [\n",
        "        \"Tetracycline\", \"Ampicillin\", \"Amoxicillin-Clavulanic acid\",\n",
        "        \"Cefoxitin\", \"Ceftiofur\", \"Gentamicin\", \"Ceftriaxone\", \"Chloramphenicol\"\n",
        "    ],\n",
        "    \"Staphylococcus aureus\": [\n",
        "        \"Erythromycin\", \"Methicillin\", \"Ciprofloxacin\", \"Clindamycin\", \"Penicillin\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# --- Run evaluation ---\n",
        "output_dir = \"/content/drive/MyDrive/MRSA datasets/Metadata Tables/Predicted Labels/ABRicate Evaluation\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "comparison_tables = {}\n",
        "\n",
        "for sp in species_list:\n",
        "    merged = []  # collect per-source metrics for merging\n",
        "\n",
        "    for name, path in abricate_sources.items():\n",
        "        df_pred = pd.read_csv(path, dtype=str)\n",
        "\n",
        "        print(f\"\\n=== Evaluating {name.upper()} for {sp} ===\")\n",
        "        metrics_df, conf_mats = evaluate_predictions(df_master, df_pred, sp, name=name)\n",
        "\n",
        "        # Save full metrics\n",
        "        out_csv = os.path.join(output_dir, f\"{name}_{sp.replace(' ', '_')}_metrics.csv\")\n",
        "        metrics_df.to_csv(out_csv)\n",
        "        print(f\"Saved metrics to {out_csv}\")\n",
        "\n",
        "        # Save confusion matrices\n",
        "        cm_out = os.path.join(output_dir, f\"{name}_{sp.replace(' ', '_')}_confusion_matrices.txt\")\n",
        "        with open(cm_out, \"w\") as f:\n",
        "            for drug, cm in conf_mats.items():\n",
        "                f.write(f\"\\nDrug: {drug}\\n{cm}\\n\")\n",
        "        print(f\"Saved confusion matrices to {cm_out}\")\n",
        "\n",
        "        # --- Save focused isolate table for this species ---\n",
        "        if sp in FOCUSED_DRUGS:\n",
        "            focus_drugs = FOCUSED_DRUGS[sp]\n",
        "            focus_df = metrics_df.loc[metrics_df.index.intersection(focus_drugs)]\n",
        "            focus_out = os.path.join(output_dir, f\"{name}_{sp.replace(' ', '_')}_FOCUSED_metrics.csv\")\n",
        "            focus_df.to_csv(focus_out)\n",
        "            print(f\"Saved focused metrics to {focus_out}\")\n",
        "\n",
        "        # Add source name prefix for merging\n",
        "        metrics_df = metrics_df.add_prefix(f\"{name}_\")\n",
        "        metrics_df.insert(0, \"Drug\", metrics_df.index)\n",
        "        merged.append(metrics_df.reset_index(drop=True))\n",
        "\n",
        "    # Merge all sources into one comparison table\n",
        "    merged_df = merged[0]\n",
        "    for m in merged[1:]:\n",
        "        merged_df = pd.merge(merged_df, m, on=\"Drug\", how=\"outer\")\n",
        "\n",
        "    comp_out = os.path.join(output_dir, f\"comparison_{sp.replace(' ', '_')}.csv\")\n",
        "    merged_df.to_csv(comp_out, index=False)\n",
        "    comparison_tables[sp] = merged_df\n",
        "    print(f\"Saved merged comparison table to {comp_out}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
